% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/generalized_linear_model.R
\name{generalized_linear_model}
\alias{generalized_linear_model}
\title{Fit a Penalized Generalized Linear Model}
\usage{
generalized_linear_model(
  x,
  y,
  alpha = 1,
  tune_type = "Grid_search",
  tune_folds_number = 5,
  tune_folds = NULL,
  tune_loss_function = NULL,
  tune_grid_proportion = 1,
  tune_bayes_samples_number = 10,
  tune_bayes_iterations_number = 10,
  lambdas_number = 100,
  records_weights = NULL,
  standardize = TRUE,
  fit_intercept = TRUE,
  validate_params = TRUE,
  seed = NULL,
  verbose = TRUE
)
}
\arguments{
\item{x}{(\code{matrix}) The predictor (independet) variable(s). It must be a
numeric matrix. You can use \code{\link[=to_matrix]{to_matrix()}} function to convert your data to
a design \code{matrix}.}

\item{y}{(\code{data.frame} | \code{vector} | \code{matrix}) The response (dependent)
variable(s). If it is a \code{data.frame} or a \code{matrix} with 2 or more columns,
a multivariate model is assumed, a univariate model otherwise. In
univariate models if \code{y} is \code{character}, \code{logical} or \code{factor} a
categorical response is assumed. When the response is categorical with only
two classes a logistic regression is assumed, with more than two classes a
multinomial regression. When the response variable is numeric with only
integers values greater or equals than zero a poisson regression is
assumed, multiple regression otherwise. In multivariate models all
responses are coerced to numeric and a multi-response gaussian regression
is assumed.}

\item{alpha}{(\code{numeric}) (\strong{tunable}) The elasticnet mixing parameter, with
0 <= \code{alpha} <= 1. The penalty is defined as:

\figure{glmnet_penalty.png}{(1 - \alpha)/2 ||\beta||_2^2 + \alpha ||\beta||_1}

\code{alpha = 0} is the lasso penalty, \code{alpha = 1} is the ridge penalty and \verb{0 < alpha < 1} is the elasticnet penalty. 1 by default.}

\item{tune_folds_number}{(\code{numeric(1)}) The number of folds to tune each
combination in the grid (k in k-fold cross validation). 5 by default.}

\item{tune_folds}{(\code{list}) Custom folds for tuning. It must be a \code{list} of
\code{list}'s where each entry will represent a fold. Each inner \code{list} has to
contain the fields \code{"training"} and \code{"testing"} with numeric vectors of
indices of those entries to be used as training and testing in each fold.
Note that when this parameter is set \code{tune_cv_type}, \code{tune_folds_number}
and \code{tune_testing_proportion} are ignored. \code{NULL} by default.}

\item{tune_loss_function}{(\code{character(1)}) (case not sensitive) The loss
function to use in tuning. The options are \code{"mse"}, \code{"maape"}, \code{"mae"},
\code{"nrmse"} or \code{"rmse"} when \code{y} is a numeric response variable,
\code{"accuracy"} or \code{"kappa_coeff"} when \code{y} is a categorical response
variable (including binary) and \code{"f1_score"}, \code{"roc_auc"} or \code{"pr_auc"}
when \code{y} is a binary response variable. \code{NULL} by default which uses
\code{"mse"} for numeric variables and \code{"accuracy"} for categorical variables.}

\item{tune_grid_proportion}{(\code{numeric(1)}) A number > 0 and <= 1 to specify
the proportion of combinations to sample from the grid and evaluate in
tuning (useful when the grid is big). 1 by default.}

\item{lambdas_number}{(\code{numeric(1)}) The number of lambda values to be
generated and evaluated in tuning. If \code{lambda} is provided, this parameter
is ignored. 100 by default.}

\item{records_weights}{(\code{numeric}) Observation weights. \code{NULL} by default (1
for each observation).}

\item{standardize}{(\code{logical(1)}) Should the \code{x} variables be standardized?
The coefficients are always returned on the original scale. If variables
are in the same units already, you might not wish to standardize. \code{TRUE} by
default.}

\item{fit_intercept}{(\code{logical(1)}) Should intercept be fitted? \code{TRUE} by
default.}

\item{validate_params}{(\code{logical(1)}) Should the parameters be validated? It
is not recommended to set this parameter to \code{FALSE} because if something
fails a non meaningful error is going to be thrown. \code{TRUE} by default.}

\item{seed}{(\code{numeric(1)}) A value to be used as internal seed for
reproducible results. \code{NULL} by default.}

\item{verbose}{(\code{logical(1)}) Should the progress information be printed?
\code{TRUE} by default.}

\item{tune_cv_type}{(\code{character(1)}) (case not sensitive) The type of cross
validation to tune the model. The options are \code{"K_fold"} and
\code{"Random"}. \code{"K_fold"} by defaul.}

\item{tune_testing_proportion}{(\code{numeric(1)}) A number > 0 and < 1 to
specify the proportion of records to use as validation set when
\code{tune_cv_type} is \code{"Random"}. 0.2 by default.}
}
\value{
An object of class \code{"GeneralizedLinearModel"} that inherits from classes
\code{"Model"} and \code{"R6"} with the fields:
\itemize{
\item \code{fitted_model}: An object of class \code{\link[glmnet:glmnet]{glmnet::glmnet()}} with the model.
\item \code{x}: The final \code{matrix} used to fit the model.
\item \code{y}: The final \code{vector} or \code{matrix} used to fit the model.
\item \code{hyperparams}: A \code{list} with all the provided hyperparameters.
\item \code{hyperparams_grid}: A \code{data.frame} with all the computed combinations of
hyperparameters and with one more column called \code{"loss"} with the value of
the loss function for each combination. The grid is ordered ascendingly by
loss value (the lower the better).
\item \code{best_hyperparams}: A \code{list} with the combination of hyperparameter with
the lowest loss value (the first row in \code{hyperparams_grid}).
\item \code{execution_time}: A \code{difftime} object with the total time taken to tune and
fit the model.
\item \code{removed_rows}: A \code{numeric} vector with the records' indices (in the
provided position) that were deleted and not taken in account in tunning
nor training.
\item \code{removed_x_cols}: A \code{numeric} vector with the columns' indices (in the
provided position and after the design matrix creation) that were deleted
and not taken in account in tunning nor training.
\item \code{...}: Some other parameters for internal use.
}
}
\description{
\code{generalized_linear_model()} is a wrapper of the \code{\link[glmnet:glmnet]{glmnet::glmnet()}} function
with the ability to tune the hyperparameters (grid search) in a simple way.
It fits univariate models for continuous, count, binary and categorical
response variables and multivariate models for numeric responses only.

All the parameters marked as (\strong{tunable}) accept a vector of values with
wich the grid is generated for tuning. The returned object contains a
\code{data.frame} with the hyperparameter grid. In the end the best combination of
hyperparameters is used to fit the final model, which is also returned and
can be used to make new predictions.
}
\details{
You have to consider that before tuning all columns without variance
(where all the records has the same value) are removed. Such columns
positions are returned in the \code{removed_x_cols} field of the returned object.

All records with missing values (\code{NA}), either in \code{x} or in \code{y} will be
removed. The positions of the removed records are returned in the
\code{removed_rows} field of the returned object.

\subsection{Tuning}{

The hyperparameters grid to evaluate in tuning is generated with the
cartesian product of all the provided values (all the posible combinations)
in all \strong{tunable} parameters. If only one value of each \strong{tunable}
parameter is provided no tuning is done. \code{tune_grid_proportion} allows you to
specify the proportion of all combinations you want to sample and tune, by
default all combinations (1) are evaluated.

The tuning algorithm works as follows:

\figure{tuning_algorithm.png}{Tuning algorithm}
}

Note that in univariate models with a numeric response variable \code{\link[=mse]{mse()}} (Mean
Squared Error) is used as loss function. In univariate models with a
categorical response variable (either binary or with more than two
categories) \code{\link[=pcic]{pcic()}} (Proportion of Cases Incorrectly Classified) is used.
}
\examples{
\dontrun{
# Fit with all default parameters
model <- generalized_linear_model(to_matrix(iris[, -5]), iris$Species)

# With tuning
model <- generalized_linear_model(
  to_matrix(iris[, -1]),
  iris$Sepal.Length,
  alpha = c(0, 0.5, 1),
  lambdas_number = 10
)

predictions <- predict(model, to_matrix(iris[, -1]))
predictions$predicted

# See the whole grid
model$hyperparams_grid

# Multivariate analysis
model <- generalized_linear_model(
  x = to_matrix(iris[, -c(1, 5)]),
  y = iris[, c(1, 5)],
  lambdas = c(0.1, 0.2, 0.3, 0.4)
)
}

}
\seealso{
\code{\link[=predict.Model]{predict.Model()}}, \code{\link[=coef.Model]{coef.Model()}}

Other models: 
\code{\link{bayesian_model}()},
\code{\link{deep_learning}()},
\code{\link{generalized_boosted_machine}()},
\code{\link{partial_least_squares}()},
\code{\link{random_forest}()},
\code{\link{support_vector_machine}()}
}
\concept{models}
